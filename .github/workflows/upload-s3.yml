# Upload object to S3
name: upload-s3

on:
  workflow_call:
    secrets:
      AWS_ROLE_TO_ASSUME:
        description: "ARN of the AWS role to assume"
        required: true

    inputs:
      # TODO: check if runner label(s) exist in the org/repo
      runs-on:
        description: "Type of runner(s) to use (comma separated)"
        type: string
        required: false
        default: "ubuntu-latest"

      artifact-name:
        description: "Name of the file to download from artifact (& upload to S3)"
        type: string
        required: true

      s3-bucket-name:
        description: "Name of the S3 bucket to upload to"
        type: string
        required: true

      s3-prefix:
        description: "Name of the S3 bucket prefix (subfolder) to upload to"
        type: string
        required: true

env:
  DOWNLOADS_FOLDER_PATH: "./downloads/artifacts"

permissions:
  id-token: write # This is required for OIDC requesting the JWT
  contents: read # This is required for actions/checkout

jobs:
  upload-to-s3:
    runs-on: ${{ inputs.runs-on || 'ubuntu-latest' }}

    # defaults:
    #   run:
    #     shell: pwsh # use powershell as default shell for all steps

    steps:
      - name: Log inputs
        shell: pwsh
        run: |
          echo "runs-on: ${{ inputs.runs-on }}"
          echo "artifact-name: ${{ inputs.artifact-name }}"
          echo "s3-bucket-name: ${{ inputs.s3-bucket-name }}"
          echo "s3-prefix: ${{ inputs.s3-prefix }}"

      # ********** Download artifact **********
      - name: Download artifact file
        uses: actions/download-artifact@v3
        with:
          name: ${{ inputs.artifact-name }}
          path: ${{ env.DOWNLOADS_FOLDER_PATH }}

      # ********** Upload to S3 **********
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          role-session-name: UploadReleaseToS3
          aws-region: eu-central-1

      # Set shell:pwsh so that cmds below work on both Windows & Linux runners.
      # (NOTE: Windows runners can't access bash shell - "Access is denied.")

      # NOT NEEDED?? As release-drafter step creates a new version even if no new changes are found.
      - name: Check if file already exists in S3
        run: |
          # STEP 1: Get S3 objects that start with same artifact-name
          echo "Artifact Name: ${{ inputs.artifact-name }}"
          $existingObjs = (aws s3api list-objects-v2 --bucket "${{ inputs.s3-bucket-name }}" --prefix "${{ inputs.s3-prefix }}" --query "Contents[?starts_with(Key, '${{ inputs.artifact-name }}')].Key" --output text)
          echo "S3 Objects with same File name: $existingObjs"

          # STEP 2: If any objects were found, throw error
          if ($existingObjs -and ($existingObjs -ne 'None')) {
            throw "File already exists in S3."
          }

      - name: Upload new release folder (zipped) to S3
        run: aws s3 cp "${{ env.DOWNLOADS_FOLDER_PATH }}/${{ inputs.artifact-name }}" "s3://${{ inputs.s3-bucket-name }}/${{ inputs.s3-prefix }}/${{ inputs.artifact-name }}"

      - name: Delete downloaded artifact file
        run: Remove-Item -Path "${{ env.DOWNLOADS_FOLDER_PATH }}/${{ inputs.artifact-name }}" -Force
