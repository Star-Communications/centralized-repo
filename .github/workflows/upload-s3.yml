# Upload object to S3
name: upload-s3

on:
  workflow_call:
    secrets:
      AWS_ROLE_TO_ASSUME:
        description: "ARN of the AWS role to assume"
        required: true

    inputs:
      # TODO: check if runner label(s) exist in the org/repo
      runs-on:
        description: "Type of runner(s) to use (comma separated)"
        type: string
        required: false
        default: "ubuntu-latest"

      upload-file-path:
        description: "Path of the file to upload to S3"
        type: string
        required: true

      s3-bucket-name:
        description: "Name of the S3 bucket to upload to"
        type: string
        required: true

      s3-prefix:
        description: "Name of the S3 bucket prefix (subfolder) to upload to"
        type: string
        required: true

env:
  UPLOADS_FOLDER_PATH: ""
  UPLOAD_FILE_NAME: ""

permissions:
  id-token: write # This is required for OIDC requesting the JWT
  contents: read # This is required for actions/checkout

jobs:
  upload-to-s3:
    runs-on: ${{ inputs.runs-on }}

    # Set 'shell:pwsh' so that cmds below work on both Windows & Linux runners.
    # (NOTE: Windows runners can't access bash shell - "Access is denied.")
    defaults:
      run:
        shell: pwsh # use powershell as default shell for all steps

    steps:
      # ********** Get upload path & file name **********
      - name: Get upload path & file name
        run: |
          $folderPath = Split-Path ${{ inputs.upload-file-path}} -Parent
          $fileName = Split-Path ${{ inputs.upload-file-path}} -Leaf

          echo "UPLOADS_FOLDER_PATH=$folderPath" >> $env:GITHUB_ENV
          echo "UPLOAD_FILE_NAME=$fileName" >> $env:GITHUB_ENV
          
          echo "Folder Path: $folderPath"
          echo "File Name: $fileName"

      # ********** Download artifact **********
      - name: Download artifact file
        uses: actions/download-artifact@v3
        continue-on-error: true # if no artifact is found, continue with next steps
        with:
          name: ${{ env.UPLOAD_FILE_NAME }}
          path: ${{ env.UPLOADS_FOLDER_PATH }}

      # ********** Upload to S3 **********
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-region: eu-central-1
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          role-session-name: UploadReleaseToS3

      # NOT NEEDED?? As release-drafter step creates a new version even if no new changes are found.
      - name: Check if file already exists in S3
        run: |
          # STEP 1: Get S3 objects that start with same upload-file-name
          echo "Artifact Name: ${{ env.UPLOAD_FILE_NAME }}"
          $existingObjs = (aws s3api list-objects-v2 --bucket "${{ inputs.s3-bucket-name }}" --prefix "${{ inputs.s3-prefix }}" --query "Contents[?starts_with(Key, '${{ env.UPLOAD_FILE_NAME }}')].Key" --output text)
          echo "S3 Objects with same File name: $existingObjs"

          # STEP 2: If any objects were found, throw error
          if ($existingObjs -and ($existingObjs -ne 'None')) {
            throw "File already exists in S3."
          }

      - name: Upload new release folder (zipped) to S3
        run: aws s3 cp "${{ env.UPLOADS_FOLDER_PATH }}/${{ env.UPLOAD_FILE_NAME }}" "s3://${{ inputs.s3-bucket-name }}/${{ inputs.s3-prefix }}/${{ env.UPLOAD_FILE_NAME }}"

      - name: Delete downloaded artifact file
        run: Remove-Item -Path "${{ env.UPLOADS_FOLDER_PATH }}/${{ env.UPLOAD_FILE_NAME }}" -Force
