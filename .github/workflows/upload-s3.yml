# Upload object to S3
name: upload-s3

on:
  workflow_call:
    secrets:
      AWS_ROLE_TO_ASSUME:
        description: "ARN of the AWS role to assume"
        required: true

    inputs:
      # TODO: check if runner label(s) exist in the org/repo
      runs-on:
        description: "Type of runner(s) to use (comma separated)"
        type: string
        required: false
        default: "ubuntu-latest"

      artifact-name:
        description: "Name of the file to download from artifact (& upload to S3)"
        type: string
        required: true

      s3-bucket-name:
        description: "Name of the S3 bucket to upload to"
        type: string
        required: true

      s3-prefix:
        description: "Name of the S3 bucket prefix (subfolder) to upload to"
        type: string
        required: true

      latest-marker:
        description: "Latest marker to remove from S3 object name (e.g. '-latest')"
        type: string
        required: false
        default: ""

env:
  DOWNLOADS_FOLDER_PATH: "./downloads/artifacts"

permissions:
  id-token: write # This is required for OIDC requesting the JWT
  contents: read # This is required for actions/checkout

jobs:
  upload-to-s3:
    runs-on: ${{ inputs.runs-on || 'ubuntu-latest' }}

    steps:
      - name: Log runner label(s)
        run: |
          echo "runs-on: ${{ inputs.runs-on || 'ubuntu-latest' }}"

      # ********** Download artifact **********
      - name: Download artifact file
        uses: actions/download-artifact@v3
        with:
          name: ${{ inputs.artifact-name }}
          path: ${{ env.DOWNLOADS_FOLDER_PATH }}

      # ********** Upload to S3 **********
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          role-session-name: UploadReleaseToS3
          aws-region: eu-central-1

      # Set shell:pwsh so that cmds below work on both Windows & Linux runners.
      # (NOTE: Windows runners can't access bash shell - "Access is denied.")

      # NOT NEEDED?? As release-drafter step creates a new version even if no new changes are found.
      - name: Check if file already exists in S3
        shell: pwsh
        run: |
          # STEP 1: Get S3 objects that start with same artifact-name
          echo "Artifact Name: ${{ inputs.artifact-name }}"
          $existingObjs = (aws s3api list-objects-v2 --bucket "${{ inputs.s3-bucket-name }}" --prefix "${{ inputs.s3-prefix }}" --query "Contents[?starts_with(Key, `${{ inputs.artifact-name }}`)].Key" --output text)
          echo "S3 Objects with same File name: $existingObjs"

          # STEP 2: If any objects were found, throw error
          if ($existingObjs) {
            throw "File already exists in S3."
          }

      - name: Upload new release folder (zipped) to S3 (add 'latest-marker')
        run: aws s3 cp "${{ env.DOWNLOADS_FOLDER_PATH }}/${{ inputs.artifact-name }}" "s3://${{ inputs.s3-bucket-name }}/${{ inputs.s3-prefix }}/${{ inputs.artifact-name }}${{ inputs.latest-marker }}"

      - name: Remove 'latest-marker' from any S3 object name (except latest uploaded one)
        if: ${{ inputs.latest-marker != '' }}
        shell: pwsh
        run: |
          # STEP 1: Get S3 objects with 'latest-marker'   
          $objsWithLatestMarker = (aws s3api list-objects-v2 --bucket "${{ inputs.s3-bucket-name }}" --prefix "${{ inputs.s3-prefix }}" --query "reverse(sort_by(Contents[?ends_with(Key, '${{ inputs.latest-marker }}')], &LastModified)[].Key)" --output text)

          # STEP 2: Check if any objects were found
          echo "S3 Objects containing 'latest-marker': $objsWithLatestMarker"

          if ($objsWithLatestMarker) {
            # STEP 3: Convert object keys (string) to array
            $objsWithLatestMarkerArray = $objsWithLatestMarker.Split()

            # STEP 4: Exit if less than 2 objects were found (this means only last uploaded object has 'latest-marker' so no need to rename)
            if ($objsWithLatestMarkerArray.Length -lt 2) {
              echo "Only 1 object containing 'latest-marker' found in S3 bucket. No need to rename."
              exit 0
            }

            # STEP 5: Remove first item from array (to keep marker on the latest uploaded object)
            $objsWithLatestMarkerArray = $objsWithLatestMarkerArray[1..($objsWithLatestMarkerArray.Length-1)]
            echo "Objects to rename (after removing last modified object): $objsWithLatestMarkerArray"

            foreach ($object in $objsWithLatestMarkerArray) {
              $newObjName = $object.Replace("${{ inputs.s3-prefix }}/","").Replace("${{ inputs.latest-marker }}","")
              echo "Old object name: $object"
              echo "New object name: $newObjName"
              
              # STEP 6: If oldObj & newObj are not equal, remove 'latest-marker' (rename object)
              if ($object -ne $newObjName) {
                aws s3 mv "s3://${{ inputs.s3-bucket-name }}/$object" "s3://${{ inputs.s3-bucket-name }}/${{ inputs.s3-prefix }}/$newObjName"
              }
            }
          } else {
            echo "No objects containing 'latest-marker' found in S3 bucket."
          }

    #   - name: Delete downloaded artifact file
    #     shell: pwsh
    #     run: Remove-Item -Path "${{ env.DOWNLOADS_FOLDER_PATH }}/${{ inputs.artifact-name }}" -Force
