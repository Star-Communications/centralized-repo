name: cd-deploy-container

on:
  workflow_call:
    secrets:
      AWS_ROLE_TO_ASSUME:
        description: "ARN of the AWS role to assume"
        required: true

    inputs:
      # TODO: check if runner label(s) exist in the org/repo
      runs-on:
        description: "The type of runner(s) to use (comma separated)"
        type: string
        required: true

      linux-user:
        description: "Linux user to use for the project folder path"
        type: string
        required: true

      target-version:
        description: "Version to deploy (if not of latest)"
        type: string
        required: true

      s3-bucket:
        description: "Name of the S3 bucket to download from"
        type: string
        required: true

      project-name:
        description: "Name of the project"
        type: string
        required: true

      project-bundle-name:
        description: "Name of the project bundle"
        type: string
        required: true

      # if path to downloaded release is "C:\actions-runner\_work\MyProj\downloads\s3\my-proj\my-proj-v0.1.29-latest",
      # then "download-release.outputs.downloaded-name-job-output" = "my-proj-v0.1.29-latest"

# disable permissions for all scopes (except for id-token)
permissions:
  id-token: write # this is required for OIDC requesting the JWT

jobs:
  # ---------- JOB ----------
  # log the outputs of the previous job & set outputs for the next job
  pre-deploy:
    runs-on: ${{ inputs.runs-on }}

    outputs:
      project-folder-path: ${{ steps.set-output-vars.outputs.project-folder-path }}

    defaults:
      run:
        shell: pwsh # use powershell as default shell for all steps

    steps:
      - name: Set output variables for next job (depending on the runner's OS)
        id: set-output-vars
        run: |
          if ("${{ runner.os }}" -eq 'Linux') {
            $projFolderPath = "/home/${{ inputs.linux-user }}/STAR-COM/${{ inputs.project-name }}"
          }
          else {
            $projFolderPath = "C:/STAR-COM/${{ inputs.project-name }}"
          }

          echo "project-folder-path=$projFolderPath" >> $env:GITHUB_OUTPUT
          echo "projFolderPath = $projFolderPath"

      - name: Ensure folder structure exists (if not already)
        run: |
          if ("${{ runner.os }}" -eq 'Linux') {
            mkdir -p "/home/${{ inputs.linux-user }}/STAR-COM/${{ inputs.project-name }}/installation-files"
          }
          else {
            mkdir -p "C:/STAR-COM/${{ inputs.project-name }}/installation-files"
          }

  download-release:
    needs: pre-deploy
    uses: ./.github/workflows/download-s3.yml
    with:
      runs-on: ${{ inputs.runs-on }}
      s3-bucket: ${{ inputs.s3-bucket }}
      s3-prefix: ${{ inputs.project-name }}
      # <condition> && <true-value> || <false-value>
      s3-obj-filter: ${{ contains(inputs.target-version, 'latest') && ' ' || inputs.target-version }}
      download-path: "${{ needs.pre-deploy.outputs.project-folder-path }}/installation-files/releases"
      unzip-file: true
    secrets:
      AWS_ROLE_TO_ASSUME: ${{ secrets.AWS_ROLE_TO_ASSUME }}
    # the job returns the following outputs:
    #   downloaded-name-job-output:

  deploy-container:
    runs-on: ${{ inputs.runs-on }}

    needs: [pre-deploy, download-release]

    defaults:
      run:
        shell: pwsh # use powershell as default shell for all steps

    steps:
      - name: Log 'download-release' job output
        run: |
          echo "downloaded-name-job-output: ${{ needs.download-release.outputs.downloaded-name-job-output }}"

      # ********** Build new image & run new container **********
      # "docker-compose.auth-server.prod.yml"

      - name: Stop existing container(s)
        run: docker compose --file "${{ needs.pre-deploy.outputs.project-folder-path}}/installation-files/docker-files/docker-compose.${{ inputs.project-name}}.prod.yml" down
        # 'continue-on-error' in case of first time installation & there are no 'docker-files' yet
        continue-on-error: true

      - name: Backup old env/appsettings files
        run: |
          $envFiles = Get-ChildItem -Path "${{ needs.pre-deploy.outputs.project-folder-path }}/installation-files/dist" -Filter "*.env" -Recurse
          $appsettingsFiles = Get-ChildItem -Path "${{ needs.pre-deploy.outputs.project-folder-path }}/installation-files/publish" -Filter "appsettings*.json" -Recurse

          $backupFolder = "${{ needs.pre-deploy.outputs.project-folder-path }}/installation-files/env-file-backup"
          New-Item -Path $backupFolder -ItemType Directory -Force

          foreach ($envFile in $envFiles) {
            Copy-Item -Path $envFile.FullName -Destination $backupFolder -Force
          }

          foreach ($appsettingsFile in $appsettingsFiles) {
            Copy-Item -Path $appsettingsFile.FullName -Destination $backupFolder -Force
          }

      - name: Overwrite old build/publish & docker files with new release files
        run: |
          Copy-Item -Path "${{ needs.pre-deploy.outputs.project-folder-path }}/installation-files/releases/${{ needs.download-release.outputs.downloaded-name-job-output }}/*" -Destination "${{ needs.pre-deploy.outputs.project-folder-path }}/installation-files/" -r -Force

      - name: Restore old env/appsettings files
        run: |
          $backupFolder = "${{ needs.pre-deploy.outputs.project-folder-path }}/installation-files/env-file-backup"

          $envFiles = Get-ChildItem -Path $backupFolder -Filter "*.env" -Recurse
          $appsettingsFiles = Get-ChildItem -Path $backupFolder -Filter "appsettings*.json" -Recurse

          foreach ($envFile in $envFiles) {
            Copy-Item -Path $envFile.FullName -Destination "${{ needs.pre-deploy.outputs.project-folder-path }}/installation-files/dist" -Force
          }

          foreach ($appsettingsFile in $appsettingsFiles) {
            Copy-Item -Path $appsettingsFile.FullName -Destination "${{ needs.pre-deploy.outputs.project-folder-path }}/installation-files/publish" -Force
          }

      - name: Start new container (docker-compose up -force build)
        run: docker compose --file "${{ needs.pre-deploy.outputs.project-folder-path}}/installation-files/docker-files/docker-compose.${{ inputs.project-name}}.prod.yml" up -d --build

    #   - name: Clean up unused containers & images
    #     run: |
    #       # STEP 1: docker system prune (remove all unused containers, networks, images (both dangling and unreferenced), and optionally, volumes)
    #       docker system prune -f

    #       # STEP 2: docker image prune (remove all dangling images)
    #       docker image prune -f
